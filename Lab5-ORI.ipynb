{"cells":[{"cell_type":"markdown","source":["# LAB 5 - Deep Computer Vision (Multiclass CNNs) using Pytorch for Dermatology\n","The objective of this lab is to understand the fundamentals of convolutional neural networks before approaching other deep learning architectures"],"metadata":{"id":"ijgnAf9Xn9rW"}},{"cell_type":"markdown","source":["#### Project Info\n","\n"," ->Copyright 2024 Luis R Soenksen\n","\n"," ->Last Update: March 24, 2024\n","\n","```\n","**Licensed under the Apache License, Version 2.0**\n","You may not use this file except in compliance with the License. You may obtain a copy of the License at\n","https://www.apache.org/licenses/LICENSE-2.0\n","Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n","```\n","\n","<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Compatible with Google Colab</a>      \n","    </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/lrsoenksen/\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Visit my GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://pytorch.org\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/PyTorch_logo_black.svg/488px-PyTorch_logo_black.svg.png\" width=\"150px\"/>Built with Pytorch </a>\n","  </td>\n","</table>"],"metadata":{"id":"6IzsgbTzhotv"}},{"cell_type":"markdown","source":["------------------------------------------------------"],"metadata":{"id":"nasy57AQCmYh"}},{"cell_type":"markdown","source":["### **Step 0) Setup system and import required packages**"],"metadata":{"id":"AYgtRuYZCeet"}},{"cell_type":"code","source":["!pip install medmnist\n","!pip install torchmetrics"],"metadata":{"id":"6M0p4qSJ4lZt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Deep learning packages\n","import torch\n","import torch.nn as nn\n","from torch import utils\n","from torch import optim\n","from torch import device\n","from torch import inference_mode\n","from torch.utils.data import DataLoader\n","import torchvision\n","from torchvision import transforms\n","from torchmetrics import ConfusionMatrix\n","\n","# Data management and Plotting\n","import numpy\n","import tqdm\n","from tqdm.auto import tqdm\n","import matplotlib.pyplot as plt\n","from textwrap import wrap\n","from timeit import default_timer as timer\n","import mlxtend\n","from mlxtend.plotting import plot_confusion_matrix\n","\n","# Import MedMNIST\n","import medmnist\n","from medmnist import INFO, Evaluator\n","print(f\"MedMNIST v{medmnist.__version__} @ {medmnist.HOMEPAGE}\")"],"metadata":{"id":"hdUc7IG3n_EX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get CPU or GPU device for training\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device = torch.device(device)"],"metadata":{"id":"Knj6HfvUXgm0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Step 1) Load data**\n","**Dataset of Dermoscopy skin diseases**\n","\n","MedMNIST, is a large-scale MNIST-like collection of standardized biomedical images, including 12 datasets for 2D and 6 datasets for 3D. All images are pre-processed into 28x28 (2D) or 28x28x28 (3D) with the corresponding classification labels, so that no background knowledge is required for users. Covering primary data modalities in biomedical images, MedMNIST is designed to perform classification on lightweight 2D and 3D images with various data scales (from 100 to 100,000) and diverse tasks (binary/multi-class, ordinal regression and multi-label). The resulting dataset, consisting of approximately 708K 2D images and 10K 3D images in total, could support numerous research and educational purposes in biomedical image analysis, computer vision and machine learning. We benchmark several baseline methods on MedMNIST, including 2D / 3D neural networks and open-source / commercial AutoML tools. This example allows you to explore building models for most applications in MedMNIST.\n","\n","For this specific example we will first use DermMNIST Data Modality is Dermatoscope, which is a Multi-Class (7) dermatology disease identification task with a good Number of Samples: 10,015 provided in the publication Philipp Tschandl, Cliff Rosendahl, et al., \"The ham10000 dataset, a large collection of multisource dermatoscopic images of common pigmented skin lesions,\" Scientific data, vol. 5, pp. 180161, 2018. Noel Codella, Veronica Rotemberg, et al., “Skin Lesion Analysis Toward Melanoma Detection 2018: A Challenge Hosted by the International Skin Imaging Collaboration (ISIC)”, 2018, arXiv:1902.03368.\n","\n","\n","![overview.jpg](https://medmnist.com/assets/v2/imgs/overview.jpg)\n","\n","\n","\n","Motivation:\n","\n","*   To reduce the burden for expert dermatologists in resource-constrained regions and improve diagnostic accuracy.\n","\n","\n","Inputs:\n","*   Dermatoscopic images (10,015) across 7 classes of benighnand mal,ignant lesions from the HAM10000 dataset.\n","\n","\n","Outputs:\n","*   Clinical dictamination\n","\n","\n","References:\n","\n","1.   Philipp Tschandl, Cliff Rosendahl, et al., \"The ham10000 dataset, a large collection of multisource dermatoscopic images of common pigmented skin lesions,\" Scientific data, vol. 5, pp. 180161, 2018.\n","\n","2.   Noel Codella, Veronica Rotemberg, et al., “Skin Lesion Analysis Toward Melanoma Detection 2018: A Challenge Hosted by the International Skin Imaging Collaboration (ISIC)”, 2018, arXiv:1902.03368.\n"],"metadata":{"id":"3z1J4OhWC-r6"}},{"cell_type":"code","source":["## Download and Split Datasets\n","data_flag = 'dermamnist'\n","\n","# Other possible data to use\n","# data_flag = 'pathmnist'\n","# data_flag = 'chestmnist'\n","# data_flag = 'dermamnist'\n","# data_flag = 'octmnist'\n","# data_flag = 'pneumoniamnist'\n","# data_flag = 'retinamnist'\n","# data_flag = 'breastmnist'\n","# data_flag = 'bloodmnist'\n","# data_flag = 'tissuemnist'\n","# data_flag = 'organamnist'\n","# data_flag = 'organcmnist'\n","# data_flag = 'organsmnist'\n","\n","# Get data info\n","info = INFO[data_flag]\n","DataClass = getattr(medmnist, info['python_class'])\n","\n","# Number of image channels\n","n_channels = info['n_channels']\n","print(f\"number of channels: {n_channels}\")\n","\n","# Number of classes\n","n_classes = len(info['label'])\n","print(f\"number of classes: {n_classes}\")\n","\n","# Number of hidden neurons in model\n","hidden_units = 128\n","print(f\"number of hidden units: {hidden_units}\")\n","\n","# Get the class names from the dataset\n","class_names = info['label']\n","print(f\"class names: {class_names}\")\n","\n","# Transform to feed to NN\n","data_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[.5], std=[.5])\n","    ])\n","\n","# Data split\n","train_data = DataClass(split='train', transform=data_transform, download=True)\n","val_data = DataClass(split='val', transform=data_transform, download=True)\n","test_data = DataClass(split='test', transform=data_transform, download=True)\n","\n","# Data into dataloader form\n","BATCH_SIZE = 128\n","train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n","val_dataloader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=True)\n","test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)"],"metadata":{"id":"gpcsfZqj45RZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display characteristics of data\n","train_data, test_data, val_data\n","print(train_data)\n","print(\"===================\")\n","print(test_data)\n","print(\"===================\")\n","print(val_data)\n","print(\"===================\")"],"metadata":{"id":"5x2oKUzyYZWV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check dataloader\n","print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n","print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n","print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\n","print(f\"Length of val dataloader: {len(val_dataloader)} batches of {BATCH_SIZE}\")"],"metadata":{"id":"ls2GyCWNZde_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot some data samples with labels\n","fig, axs = plt.subplots(nrows=2, ncols=5, figsize=(15, 10))\n","axs = axs.ravel()\n","\n","# Iterate through images in train dataloader\n","i = 0\n","while i < len(axs):\n","  images, labels = next(iter(train_dataloader))\n","  axs[i].imshow(images[0].permute(1, 2, 0).numpy())\n","  axs[i].set_title(\"\\n\".join(wrap(f\"Label: {class_names[str(labels[0].item())]}\"+ \" [\" + str(labels[0].item())+ \"]\", 20)), wrap=True)\n","  i += 1\n","\n","plt.suptitle(f\"First {len(axs)} training examples\")\n","plt.show()"],"metadata":{"id":"G_dl38zOrE6x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Show montage of all types of images\n","train_data.montage(length=20)"],"metadata":{"id":"Cafbv9S9YaKZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Step 2) Define and Train Model**"],"metadata":{"id":"gHNguEv-Qq24"}},{"cell_type":"code","source":["## Making the CNN\n","class cnn(torch.nn.Module):\n","    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n","        super().__init__()\n","\n","        # Layer 1: Conv layer with BatchNorm and ReLU\n","        self.layer1 = #TO DO\n","\n","        # Layer 2: Another Conv layer followed by BatchNorm, ReLU, and MaxPooling\n","        self.layer2 = #TO DO\n","\n","        # Layer 3: Conv layer with 4x more filters, followed by BatchNorm and ReLU\n","        self.layer3 = #TO DO\n","\n","        # Layer 4: Similar Conv layer followed by BatchNorm and ReLU\n","        self.layer4 = #TO DO\n","\n","        self.layer5 = nn.Sequential(\n","            nn.Conv2d(in_channels=hidden_units*4,\n","                      out_channels=hidden_units*4,\n","                      kernel_size=3,\n","                      padding=1),\n","            nn.BatchNorm2d(hidden_units*4),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2,\n","                         stride=2))\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(hidden_units*4 * 4 * 4, hidden_units*8),\n","            nn.ReLU(),\n","            nn.Linear(hidden_units*8, hidden_units*8),\n","            nn.ReLU(),\n","            nn.Linear(hidden_units*8, n_classes))\n","\n","    def forward(self, x): #TO DO complete the code for a forward pass\n","        x =\n","        x =\n","        x =\n","        x =\n","        x =\n","        x =                       #flatten the output of the last conv layer\n","        x =                       #pass the output through the fully connected layer\n","        return x\n","\n","# Define Model and send to selected device\n","model = #TO DO\n","\n","# Setup loss and optimizer\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","# View Model\n","model"],"metadata":{"id":"nLXcKgAU0NG8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Fill the in the missing code marked as # TO DO\n","'''\n","# Define training loop functions\n","def train_step(model: torch.nn.Module,\n","               data_loader: torch.utils.data.DataLoader,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer,\n","               accuracy_fn,\n","               device: torch.device = device):\n","\n","    train_loss, train_acc = 0, 0\n","    model.to(device)\n","\n","    for batch, (X, y) in enumerate(data_loader):\n","        # need to change target shape for this medmnist data\n","        y = y.squeeze().long()\n","\n","        # Send data to selected device\n","                                           #TO DO\n","\n","        # 1. Forward pass\n","                                           #TO DO\n","\n","        # 2. loss and accuracy\n","        loss =                             #TO DO\n","        train_loss +=                      #TO DO\n","        train_acc +=                       #TO DO\n","\n","        # 3. Set gradients to zero for next iteration\n","                                           #TO DO\n","\n","        # 4. Compute gradients\n","                                           #TO DO\n","\n","        # 5. Update parameters\n","                                           #TO DO\n","\n","    # Calculate loss and accuracy per epoch\n","    train_loss /= len(data_loader)\n","    train_acc /= len(data_loader)\n","\n","    return train_loss, train_acc"],"metadata":{"id":"gH4hC3HhRFda"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Fill the in the missing code marked as # TO DO\n","'''\n","# Define test loop functions\n","def test_step(data_loader: torch.utils.data.DataLoader,\n","              model: torch.nn.Module,\n","              loss_fn: torch.nn.Module,\n","              accuracy_fn,\n","              device: torch.device = device):\n","\n","    test_loss, test_acc = 0, 0\n","    model.to(device)\n","\n","    model.eval() # eval mode for testing\n","    with torch.inference_mode(): # Inference context manager\n","        for X, y in data_loader:\n","            # need to change target shape for this medmnist data\n","            y = y.squeeze().long()\n","\n","            # Send data to selected device\n","                                                #TO DO\n","\n","            # 1. Forward pass\n","                                                #TO DO\n","\n","            # 2. Calculate loss and accuracy\n","            test_loss +=                        #TO DO\n","            test_acc +=                         #TO DO\n","\n","        # Adjust metrics and print out\n","        test_loss /= len(data_loader)\n","        test_acc /= len(data_loader)\n","\n","        return test_loss, test_acc"],"metadata":{"id":"4TLreqheaFYL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Fill the in the missing code marked as # TO DO\n","'''\n","# Define evaluation loop functions\n","def eval_func(data_loader: torch.utils.data.DataLoader,\n","              model: torch.nn.Module,\n","              loss_fn: torch.nn.Module,\n","              accuracy_fn,\n","              device: torch.device = device):\n","\n","    eval_loss, eval_acc = 0, 0\n","    model.to(device)\n","\n","    model.eval()\n","    y_preds = []\n","    y_targets = []\n","    with torch.inference_mode():\n","        for batch, (X, y) in tqdm(enumerate(data_loader)):\n","            # need to change target shape for this medmnist data\n","            y = y.squeeze().long()\n","\n","            # Send data to selected device\n","            X, y =                              #TO DO\n","\n","            # Forward pass\n","            eval_pred =                         #TO DO\n","\n","            # Find loss and accuracy\n","            eval_loss +=                        #TO DO\n","            eval_acc +=                         #TO DO\n","\n","            # Add prediction and target labels to list\n","            eval_labels =                       #TO DO\n","            y_preds.append(eval_labels)\n","            y_targets.append(y)\n","\n","        # Scale loss and acc\n","        eval_loss /= len(data_loader)\n","        eval_acc /= len(data_loader)\n","\n","        # Put predictions on CPU for evaluation\n","        y_preds=torch.cat(y_preds).cpu()\n","        y_targets=torch.cat(y_targets).cpu()\n","\n","        return {\"model_name\": model.__class__.__name__,\n","                \"loss\": eval_loss.item(),\n","                \"accuracy\": eval_acc,\n","                \"predictions\": y_preds,\n","                \"targets\": y_targets}"],"metadata":{"id":"eKoeoa4_aKMt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to calculate model run time\n","def print_train_time(start: float, end: float, device: torch.device = None):\n","    total_time = end - start\n","    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n","    return total_time"],"metadata":{"id":"YQk4sga-aMBC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Accuracy calculation function\n","def accuracy_fn(y_true, y_pred):\n","    correct = torch.eq(y_true, y_pred).sum().item()\n","    acc = (correct / len(y_pred)) * 100\n","    return acc"],"metadata":{"id":"94iLvf38aNq1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Train and Test\n","\n","# Set random seeds\n","torch.manual_seed(42)\n","\n","# Measure Time\n","train_time_start_model = timer()\n","iteration_loss_list = []\n","iteration_accuracy_list = []\n","\n","# set parameters\n","epochs = 10\n","best_loss = 10\n","\n","# call train and test function\n","for epoch in tqdm(range(epochs)):\n","    train_loss, train_acc = #TO DO\n","\n","    test_loss, test_acc = #TO DO\n","\n","    for iteration, (x, y) in enumerate(train_dataloader):\n","        iteration_loss_list.append(train_loss.item())\n","        iteration_accuracy_list.append(train_acc)\n","\n","\n","    print(f\"Epoch: {epoch} | Training loss: {train_loss:.3f} | Training acc: {train_acc:.2f} | Test loss: {test_loss:.3f} | Test acc: {test_acc:.2f}\")\n","\n","    # save best model instance\n","\n","    if test_loss < best_loss:\n","        best_loss = test_loss\n","        print(f\"Saving best model for epoch: {epoch}\")\n","        torch.save(obj=model.state_dict(),\n","                   f=\"./model.pth\")\n","\n","\n","train_time_end_model = timer()\n","total_train_time_model = print_train_time(start=train_time_start_model,\n","                                           end=train_time_end_model,\n","                                           device=device)"],"metadata":{"id":"hZoMJS2eacAs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Evaluate and visualize results\n","\n","# Load model\n","loaded_model = cnn(input_shape=n_channels,\n","                   hidden_units=hidden_units,\n","                   output_shape=n_classes).to(device)\n","\n","loaded_model.load_state_dict(torch.load(f=\"./model.pth\"))\n","\n","# get results\n","model_results =                       #call eval_func  #TO DO\n","\n","model_results\n","# points for accuracy more than 70%"],"metadata":{"id":"WI7001YjanzU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get Model predictions and true targets\n","y_targets = model_results['targets']\n","y_preds = model_results['predictions']\n","\n","# Setup confusion matrix\n","confmat = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names))\n","confmat_tensor = confmat(preds=y_preds,\n","                         target=y_targets)\n","\n","# Plot the confusion matrix\n","fix, ax = plot_confusion_matrix(\n","    conf_mat=confmat_tensor.numpy(),\n","    class_names=class_names,\n","    figsize=(10, 7)\n",")"],"metadata":{"id":"zpo8K9OiawFy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot iteration vs loss\n","plt.figure(figsize=(10, 5))\n","plt.semilogy(iteration_loss_list, label='Training Loss')\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')\n","plt.title('Iteration vs Loss')\n","plt.legend()\n","plt.show()\n","\n","# Plot iteration vs accuracy\n","plt.figure(figsize=(10, 5))\n","plt.semilogx(iteration_accuracy_list, label='Training Accuracy')\n","plt.xlabel('Iteration')\n","plt.ylabel('Accuracy')\n","plt.title('Iteration vs Accuracy')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"p4oPrBAma3-b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Step 3) Run inference on new data**"],"metadata":{"id":"Dp6mvDTzQtyZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CsuYPI3hYUiJ"},"outputs":[],"source":["torch.save(loaded_model.state_dict(), \"medmnist_cnn_pytorch.ckpt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hlZh5qpnDNbb"},"outputs":[],"source":["def visualize_and_predict(model, device, data_loader):\n","    model.eval()\n","    with torch.no_grad():\n","        # Extract the first batch of images and labels\n","        data, target = next(iter(data_loader))\n","        # Select the first image and label\n","        img, label = data[0], target[0]\n","\n","        # Visualize the image\n","        plt.imshow(img.permute(1, 2, 0).numpy())\n","        plt.title(f\"\\n\".join(wrap(f\"Actual Label: {class_names[str(label.item())]}\"+ \" [\" + str(label.item())+ \"]\", 20)))\n","        plt.show()\n","\n","        # Run inference\n","        img = #TO DO\n","        output = #TO DO  # Add batch dimension\n","        pred = #TO DO\n","\n","        print(f\"\\n\".join(wrap(f\"Predicted Label: {class_names[str(pred.item())]}\"+ \" [\" + str(pred.item())+ \"]\", 20)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WakWPaycDNbb"},"outputs":[],"source":["visualize_and_predict(loaded_model, device, test_dataloader)"]},{"cell_type":"markdown","source":["------------------------------------------------------\n","------------------------------------------------------"],"metadata":{"id":"Mrye5YBBhyy7"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1EaHHLGYESwuWs4VFjmYIiaWErYwBbH8k","timestamp":1716342513147}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}